JobBatchName = "cifar10_one_annotator$(cluster)"

executable = /bin/bash
arguments = /mnt/fast/nobackup/scratch4weeks/wa00433/projects/DivideMix/run.sh $(annotator) $(process)

universe         = docker
docker_image     = nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

log    = c$(cluster).p$(process).log
output = c$(cluster).p$(process).out
error  = c$(cluster).p$(process).error

stream_output = true
stream_error = true
should_transfer_files = YES

requirements = (CUDAGlobalMemoryMb > 4500) && \
               (HasDocker) && \
               (CUDACapability > 2.0) && \
               (CUDADeviceName == "NVIDIA GeForce RTX 2080 Ti") 
# && (machine != "aisurrey13.surrey.ac.uk") && (machine != "aisurrey14.surrey.ac.uk") && (machine != "aisurrey08.surrey.ac.uk")

# Clusters with project machines e.g cvssp-condor
# If you want to avoid ProjectOwned machine other that projects that you're part of, you can add:

# ((NotProjectOwned) || (machine == "mymachine1.eps.surrey.ac.uk") || (machine == "mymachine2.eps.surrey.ac.uk"))

# environment = "TORCH_HOME=/vol/research/deepvisrep/.cache/torch"
#environment = "mount=$ENV(PWD)"
#environment = "TORCH_HOME=/mnt/fast/nobackup/users/wa00433/.cache/torch ROOTDIR=$ENV(PWD) HF_DATASETS_CACHE=/mnt/fast/nobackup/users/wa00433/.cache/huggingface/datasets HUGGINGFACE_HUB_CACHE=/mnt/fast/nobackup/users/wa00433/.cache/huggingface/hub HF_HOME=/mnt/fast/nobackup/users/wa00433/.cache/huggingface ACCELERATE_MIXED_PRECISION=fp16"
#environment = PYTHONIOENCODING=UTF-8

request_GPUs     = 1
request_CPUs     = 4
request_memory   = 32G

#This job will complete in less than 1 hour
+JobRunTime = 72
+GPUMem = 8000

+CanCheckpoint = true

queue 1 annotator in random_label1, random_label2, random_label3
#queue 1 T_max in 200, 300, 600
#queue 1 batch_size in 128
